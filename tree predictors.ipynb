{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22b51ef-af7e-440e-9890-ee5192008425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fceba88-04c2-4634-8a50-c3c149cf25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_label_encode(series):\n",
    "    unique_values = series.unique()\n",
    "    mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    return series.map(mapping), mapping\n",
    "\n",
    "\n",
    "def data_preprocessing(primary_path, secondary_path=None, sample_ratio=0.1):\n",
    "    primary_data = pd.read_csv(primary_path).fillna(\"N/A\")\n",
    "    X_primary = primary_data.drop(columns=[\"class\"])\n",
    "    y_primary, _ = custom_label_encode(primary_data[\"class\"])\n",
    "\n",
    "    if secondary_path:\n",
    "        secondary_data = pd.read_csv(secondary_path).fillna(\"N/A\")\n",
    "        \n",
    "        # Sample only a fraction of secondary data to reduce size\n",
    "        sample_size = int(len(secondary_data) * sample_ratio)\n",
    "        secondary_data = secondary_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        X_secondary = secondary_data.drop(columns=[\"class\"])\n",
    "        y_secondary, _ = custom_label_encode(secondary_data[\"class\"])\n",
    "\n",
    "        # Ensure both datasets have the same columns\n",
    "        for col in X_primary.columns:\n",
    "            if col not in X_secondary.columns:\n",
    "                X_secondary[col] = \"N/A\"\n",
    "\n",
    "        for col in X_secondary.columns:\n",
    "            if col not in X_primary.columns:\n",
    "                X_primary[col] = \"N/A\"\n",
    "\n",
    "        # Align column order\n",
    "        X_secondary = X_secondary[X_primary.columns]\n",
    "\n",
    "        # Convert categorical columns to numeric\n",
    "        for column in X_primary.columns:\n",
    "            X_primary[column], _ = custom_label_encode(X_primary[column])\n",
    "        for column in X_secondary.columns:\n",
    "            X_secondary[column], _ = custom_label_encode(X_secondary[column])\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        X_primary_np = X_primary.to_numpy()\n",
    "        X_secondary_np = X_secondary.to_numpy()\n",
    "        y_primary_np = y_primary.to_numpy()\n",
    "        y_secondary_np = y_secondary.to_numpy()\n",
    "\n",
    "        # Merge sampled dataset\n",
    "        X_merged = np.vstack((X_primary_np, X_secondary_np))\n",
    "        y_merged = np.concatenate((y_primary_np, y_secondary_np))\n",
    "\n",
    "        return X_primary_np, y_primary_np, X_merged, y_merged\n",
    "\n",
    "    return X_primary.to_numpy(), y_primary.to_numpy(), None, None\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "def run_mushroom_classification(X_merged, y_merged):\n",
    "    \"\"\"Run complete mushroom classification experiment\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_merged, y_merged, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Determine feature types\n",
    "    feature_types = ['categorical' if isinstance(val, (str, np.str_)) else 'numerical' \n",
    "                    for val in X_merged[0]]\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search_results = perform_grid_search(X_train, y_train, X_val, y_val, feature_types)\n",
    "    \n",
    "    print(\"\\nBest parameters:\", grid_search_results['best_params'])\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    best_model = DecisionTree(**grid_search_results['best_params'])\n",
    "    best_model.fit(X_train, y_train, feature_types)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_metrics = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nTest set metrics:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    feature_importance_dict = {\n",
    "        f\"Feature {i}\": importance \n",
    "        for i, importance in enumerate(best_model.feature_importances_)\n",
    "    }\n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for feature, importance in sorted_features:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "    return best_model, grid_search_results, test_metrics\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Evaluate model performance including 0-1 loss\"\"\"\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    zero_one_loss = 1 - accuracy\n",
    "    \n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'zero_one_loss': zero_one_loss,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf3176-ec72-4b40-9588-e8eeae626ad9",
   "metadata": {},
   "source": [
    "## overfitting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ad7962-3ec4-4e6f-8fe0-a131f4ebaddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for All Configurations (Sorted by 0-1 Loss):\n",
      "================================================================================\n",
      "\n",
      "1. Validation 0-1 Loss: 0.0946\n",
      "   Training 0-1 Loss: 0.0784\n",
      "Parameters:\n",
      "  - criterion: gini\n",
      "  - max_depth: 10\n",
      "  - min_samples_leaf: 1\n",
      "  - min_impurity_decrease: 0.0\n",
      "  - ccp_alpha: 0.1\n",
      "  - prune: True\n",
      "----------------------------------------\n",
      "\n",
      "2. Validation 0-1 Loss: 0.2181\n",
      "   Training 0-1 Loss: 0.2159\n",
      "Parameters:\n",
      "  - criterion: entropy\n",
      "  - max_depth: 7\n",
      "  - min_samples_leaf: 1\n",
      "  - min_impurity_decrease: 0.0\n",
      "  - ccp_alpha: 0.0\n",
      "  - prune: False\n",
      "----------------------------------------\n",
      "\n",
      "3. Validation 0-1 Loss: 0.2371\n",
      "   Training 0-1 Loss: 0.2495\n",
      "Parameters:\n",
      "  - criterion: misclassification\n",
      "  - max_depth: 5\n",
      "  - min_samples_leaf: 5\n",
      "  - min_impurity_decrease: 0.0\n",
      "  - ccp_alpha: 0.0\n",
      "  - prune: False\n",
      "----------------------------------------\n",
      "\n",
      "4. Validation 0-1 Loss: 0.2380\n",
      "   Training 0-1 Loss: 0.2527\n",
      "Parameters:\n",
      "  - criterion: gini\n",
      "  - max_depth: 5\n",
      "  - min_samples_leaf: 1\n",
      "  - min_impurity_decrease: 0.0\n",
      "  - ccp_alpha: 0.0\n",
      "  - prune: False\n",
      "----------------------------------------\n",
      "\n",
      "5. Validation 0-1 Loss: 0.2380\n",
      "   Training 0-1 Loss: 0.2527\n",
      "Parameters:\n",
      "  - criterion: gini\n",
      "  - max_depth: 5\n",
      "  - min_samples_leaf: 1\n",
      "  - min_impurity_decrease: 0.0\n",
      "  - ccp_alpha: 0.01\n",
      "  - prune: True\n",
      "----------------------------------------\n",
      "\n",
      "6. Validation 0-1 Loss: 0.3645\n",
      "   Training 0-1 Loss: 0.3602\n",
      "Parameters:\n",
      "  - criterion: entropy\n",
      "  - max_depth: 3\n",
      "  - min_samples_leaf: 5\n",
      "  - min_impurity_decrease: 0.01\n",
      "  - ccp_alpha: 0.0\n",
      "  - prune: False\n",
      "----------------------------------------\n",
      "\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'ccp_alpha': 0.1, 'prune': True}\n",
      "\n",
      "Training final models (with and without pruning)...\n",
      "\n",
      "Evaluation Results:\n",
      "================================================================================\n",
      "\n",
      "Test set metrics (Without Pruning):\n",
      "accuracy: 0.9028\n",
      "zero_one_loss: 0.0972\n",
      "precision: 0.9413\n",
      "recall: 0.8828\n",
      "f1_score: 0.9111\n",
      "\n",
      "Test set metrics (With Pruning):\n",
      "accuracy: 0.9028\n",
      "zero_one_loss: 0.0972\n",
      "precision: 0.9413\n",
      "recall: 0.8828\n",
      "f1_score: 0.9111\n",
      "\n",
      "Feature Importance Analysis:\n",
      "================================================================================\n",
      "\n",
      "Top 5 most important features:\n",
      "Feature 12: 0.1784\n",
      "Feature 7: 0.1487\n",
      "Feature 14: 0.1162\n",
      "Feature 9: 0.1144\n",
      "Feature 22: 0.0972\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, is_categorical=False):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.is_leaf = value is not None\n",
    "        self.is_categorical = is_categorical\n",
    "        \n",
    "    def decision_function(self, x):\n",
    "        \"\"\"Decision criterion/test function\"\"\"\n",
    "        if self.is_categorical:\n",
    "            return x[self.feature] == self.threshold\n",
    "        return x[self.feature] <= self.threshold\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, criterion='gini', max_depth=5, min_samples_leaf=1, \n",
    "                 min_impurity_decrease=0.0, min_weight_fraction_leaf=0.0, ccp_alpha=0.0):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.ccp_alpha = ccp_alpha  # Added for pruning\n",
    "        self.root = None\n",
    "        self.feature_types = None\n",
    "        self.n_classes = None\n",
    "        self.feature_importances_ = None\n",
    "\n",
    "    def _calculate_split_score(self, y, left_y, right_y):\n",
    "        \"\"\"\n",
    "        Calculate the split score based on the selected criterion.\n",
    "        \"\"\"\n",
    "        if self.criterion == 'gini':\n",
    "            return self._gini_score(y, left_y, right_y)\n",
    "        elif self.criterion == 'entropy':\n",
    "            return self._entropy_score(y, left_y, right_y)\n",
    "        else:  # 'misclassification'\n",
    "            return self._misclassification_score(y, left_y, right_y)\n",
    "\n",
    "    def _gini_score(self, y, left_y, right_y):\n",
    "        \"\"\"\n",
    "        Calculate the weighted Gini impurity for a split.\n",
    "        \"\"\"\n",
    "        def gini(y_subset):\n",
    "            _, counts = np.unique(y_subset, return_counts=True)\n",
    "            probabilities = counts / len(y_subset)\n",
    "            return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "        left_weight = len(left_y) / len(y)\n",
    "        right_weight = len(right_y) / len(y)\n",
    "        return left_weight * gini(left_y) + right_weight * gini(right_y)\n",
    "\n",
    "    def _entropy_score(self, y, left_y, right_y):\n",
    "        \"\"\"\n",
    "        Calculate the weighted entropy for a split.\n",
    "        \"\"\"\n",
    "        def entropy(y_subset):\n",
    "            _, counts = np.unique(y_subset, return_counts=True)\n",
    "            probabilities = counts / len(y_subset)\n",
    "            return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "        left_weight = len(left_y) / len(y)\n",
    "        right_weight = len(right_y) / len(y)\n",
    "        return left_weight * entropy(left_y) + right_weight * entropy(right_y)\n",
    "\n",
    "    def _misclassification_score(self, y, left_y, right_y):\n",
    "        \"\"\"\n",
    "        Calculate the weighted misclassification error for a split.\n",
    "        \"\"\"\n",
    "        def misclassification(y_subset):\n",
    "            if len(y_subset) == 0:\n",
    "                return 0\n",
    "            _, counts = np.unique(y_subset, return_counts=True)\n",
    "            return 1 - np.max(counts) / len(y_subset)\n",
    "\n",
    "        left_weight = len(left_y) / len(y)\n",
    "        right_weight = len(right_y) / len(y)\n",
    "        return left_weight * misclassification(left_y) + right_weight * misclassification(right_y)\n",
    "\n",
    "    def fit(self, X, y, feature_types, prune=False):\n",
    "        \"\"\"Train the decision tree with optional pruning\"\"\"\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.feature_types = feature_types\n",
    "        self.feature_importances_ = np.zeros(X.shape[1])\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "        \n",
    "        if prune:\n",
    "            self._prune_tree(self.root, X, y)\n",
    "            \n",
    "        if np.sum(self.feature_importances_) > 0:\n",
    "            self.feature_importances_ /= np.sum(self.feature_importances_)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples = len(y)\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        if (depth >= self.max_depth or \n",
    "            len(np.unique(y)) == 1 or \n",
    "            n_samples < self.min_samples_leaf or\n",
    "            n_samples / len(y) < self.min_weight_fraction_leaf):\n",
    "            return Node(value=np.argmax(np.bincount(y)))\n",
    "\n",
    "        best_feature, best_threshold, best_score, left_indices, right_indices = self._find_best_split(X, y)\n",
    "        \n",
    "        if best_score == float('inf') or best_score < self.min_impurity_decrease:\n",
    "            return Node(value=np.argmax(np.bincount(y)))\n",
    "\n",
    "        # Record feature importance\n",
    "        self.feature_importances_[best_feature] += (best_score * n_samples)\n",
    "        \n",
    "        # Build subtrees\n",
    "        left_child = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return Node(\n",
    "            feature=best_feature,\n",
    "            threshold=best_threshold,\n",
    "            left=left_child,\n",
    "            right=right_child,\n",
    "            is_categorical=self.feature_types[best_feature] == 'categorical'\n",
    "        )\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_score = float('inf')\n",
    "        best_left_indices = None\n",
    "        best_right_indices = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            \n",
    "            if self.feature_types[feature] == 'categorical':\n",
    "                for value in unique_values:\n",
    "                    left_mask = X[:, feature] == value\n",
    "                    right_mask = ~left_mask\n",
    "                    \n",
    "                    if np.sum(left_mask) < self.min_samples_leaf or np.sum(right_mask) < self.min_samples_leaf:\n",
    "                        continue\n",
    "                    \n",
    "                    score = self._calculate_split_score(y, y[left_mask], y[right_mask])\n",
    "                    \n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_feature = feature\n",
    "                        best_threshold = value\n",
    "                        best_left_indices = np.where(left_mask)[0]\n",
    "                        best_right_indices = np.where(right_mask)[0]\n",
    "            else:\n",
    "                for threshold in unique_values:\n",
    "                    left_mask = X[:, feature] <= threshold\n",
    "                    right_mask = ~left_mask\n",
    "                    \n",
    "                    if np.sum(left_mask) < self.min_samples_leaf or np.sum(right_mask) < self.min_samples_leaf:\n",
    "                        continue\n",
    "                    \n",
    "                    score = self._calculate_split_score(y, y[left_mask], y[right_mask])\n",
    "                    \n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_feature = feature\n",
    "                        best_threshold = threshold\n",
    "                        best_left_indices = np.where(left_mask)[0]\n",
    "                        best_right_indices = np.where(right_mask)[0]\n",
    "\n",
    "        return best_feature, best_threshold, best_score, best_left_indices, best_right_indices\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_single(x, self.root) for x in X])\n",
    "\n",
    "    def _predict_single(self, x, node):\n",
    "        \"\"\"\n",
    "        Predict the class label for a single data point.\n",
    "        \"\"\"\n",
    "        if node.is_leaf:\n",
    "            return node.value\n",
    "\n",
    "        if node.decision_function(x):\n",
    "            return self._predict_single(x, node.left)\n",
    "        return self._predict_single(x, node.right)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation of the decision tree.\n",
    "        \"\"\"\n",
    "        return self._print_tree(self.root)\n",
    "\n",
    "    def _print_tree(self, node, depth=0):\n",
    "        \"\"\"\n",
    "        Recursively print the tree structure.\n",
    "        \"\"\"\n",
    "        if node.is_leaf:\n",
    "            return f\"{'  ' * depth}Leaf: Class {node.value}\\n\"\n",
    "        else:\n",
    "            return (f\"{'  ' * depth}Node: Feature {node.feature}, Threshold {node.threshold}\\n\"\n",
    "                    f\"{self._print_tree(node.left, depth + 1)}\"\n",
    "                    f\"{self._print_tree(node.right, depth + 1)}\")\n",
    "\n",
    "\n",
    "    def _prune_tree(self, node, X, y):\n",
    "        \"\"\"\n",
    "        Perform cost-complexity pruning on the tree.\n",
    "        \"\"\"\n",
    "        if node.is_leaf:\n",
    "            return\n",
    "            \n",
    "        # Prune left and right subtrees\n",
    "        if node.left:\n",
    "            self._prune_tree(node.left, X, y)\n",
    "        if node.right:\n",
    "            self._prune_tree(node.right, X, y)\n",
    "            \n",
    "        # Calculate the error before pruning\n",
    "        y_pred = self.predict(X)\n",
    "        error_before = np.mean(y_pred != y)\n",
    "        \n",
    "        # Temporarily prune the node\n",
    "        original_left = node.left\n",
    "        original_right = node.right\n",
    "        original_is_leaf = node.is_leaf\n",
    "        original_value = node.value\n",
    "        \n",
    "        node.left = None\n",
    "        node.right = None\n",
    "        node.is_leaf = True\n",
    "        node.value = np.argmax(np.bincount(y))\n",
    "        \n",
    "        # Calculate the error after pruning\n",
    "        y_pred = self.predict(X)\n",
    "        error_after = np.mean(y_pred != y)\n",
    "        \n",
    "        # Calculate the cost-complexity gain\n",
    "        gain = error_after - error_before + self.ccp_alpha\n",
    "        \n",
    "        # If the gain is positive, revert the pruning\n",
    "        if gain > 0:\n",
    "            node.left = original_left\n",
    "            node.right = original_right\n",
    "            node.is_leaf = original_is_leaf\n",
    "            node.value = original_value\n",
    "\n",
    "def calculate_zero_one_loss(y_true, y_pred):\n",
    "    \"\"\"Calculate 0-1 loss (misclassification error)\"\"\"\n",
    "    return np.mean(y_true != y_pred)\n",
    "            \n",
    "\n",
    "def perform_grid_search(X_train, y_train, X_val, y_val, feature_types):\n",
    "    \"\"\"Perform efficient grid search with selected promising parameter combinations\"\"\"\n",
    "    # Reduced parameter combinations focusing on most impactful parameters\n",
    "    selected_params = [\n",
    "        # Basic configurations\n",
    "        {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, \n",
    "         'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'prune': False},\n",
    "        \n",
    "        # Pruned version\n",
    "        {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, \n",
    "         'min_impurity_decrease': 0.0, 'ccp_alpha': 0.01, 'prune': True},\n",
    "        \n",
    "        # More conservative depth\n",
    "        {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 5, \n",
    "         'min_impurity_decrease': 0.01, 'ccp_alpha': 0.0, 'prune': False},\n",
    "        \n",
    "        # More flexible depth\n",
    "        {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, \n",
    "         'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'prune': False},\n",
    "        \n",
    "        # Misclassification criterion\n",
    "        {'criterion': 'misclassification', 'max_depth': 5, 'min_samples_leaf': 5, \n",
    "         'min_impurity_decrease': 0.0, 'ccp_alpha': 0.0, 'prune': False},\n",
    "        \n",
    "        # Heavy pruning\n",
    "        {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, \n",
    "         'min_impurity_decrease': 0.0, 'ccp_alpha': 0.1, 'prune': True},\n",
    "    ]\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, params in enumerate(selected_params, 1):\n",
    "        \n",
    "        # Separate pruning flag\n",
    "        prune = params.pop('prune')\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        model = DecisionTree(**params)\n",
    "        model.fit(X_train, y_train, feature_types, prune=prune)\n",
    "        \n",
    "        # Calculate losses\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        train_loss = calculate_zero_one_loss(y_train, y_train_pred)\n",
    "        val_loss = calculate_zero_one_loss(y_val, y_val_pred)\n",
    "        \n",
    "        # Add pruning flag back\n",
    "        params['prune'] = prune\n",
    "        \n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss\n",
    "        })\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_params = params\n",
    "    \n",
    "    # Sort results by validation loss\n",
    "    sorted_results = sorted(results, key=lambda x: x['val_loss'])\n",
    "    \n",
    "    print(\"\\nResults for All Configurations (Sorted by 0-1 Loss):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, result in enumerate(sorted_results, 1):\n",
    "        print(f\"\\n{i}. Validation 0-1 Loss: {result['val_loss']:.4f}\")\n",
    "        print(f\"   Training 0-1 Loss: {result['train_loss']:.4f}\")\n",
    "        print(\"Parameters:\")\n",
    "        for param, value in result['params'].items():\n",
    "            print(f\"  - {param}: {value}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_loss': best_loss,\n",
    "        'all_results': sorted_results\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "def run_mushroom_classification(X_merged, y_merged):\n",
    "    \"\"\"Run complete mushroom classification experiment with pruning comparison\"\"\"\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_merged, y_merged, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Determine feature types\n",
    "    feature_types = ['categorical' if isinstance(val, (str, np.str_)) else 'numerical' \n",
    "                    for val in X_merged[0]]\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search_results = perform_grid_search(X_train, y_train, X_val, y_val, feature_types)\n",
    "    \n",
    "    print(\"\\nBest parameters:\", grid_search_results['best_params'])\n",
    "    \n",
    "    # Train final model with best parameters (without pruning)\n",
    "    print(\"\\nTraining final models (with and without pruning)...\")\n",
    "    \n",
    "    # Without pruning\n",
    "    params_no_prune = grid_search_results['best_params'].copy()\n",
    "    prune_flag = params_no_prune.pop('prune')\n",
    "    \n",
    "    model_no_prune = DecisionTree(**params_no_prune)\n",
    "    model_no_prune.fit(X_train, y_train, feature_types, prune=False)\n",
    "    \n",
    "    # With pruning\n",
    "    model_with_prune = DecisionTree(**params_no_prune)\n",
    "    model_with_prune.fit(X_train, y_train, feature_types, prune=True)\n",
    "    \n",
    "    # Evaluate both models\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Without pruning\n",
    "    y_pred_no_prune = model_no_prune.predict(X_test)\n",
    "    test_metrics_no_prune = evaluate_model(y_test, y_pred_no_prune)\n",
    "    \n",
    "    print(\"\\nTest set metrics (Without Pruning):\")\n",
    "    for metric, value in test_metrics_no_prune.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # With pruning\n",
    "    y_pred_with_prune = model_with_prune.predict(X_test)\n",
    "    test_metrics_with_prune = evaluate_model(y_test, y_pred_with_prune)\n",
    "    \n",
    "    print(\"\\nTest set metrics (With Pruning):\")\n",
    "    for metric, value in test_metrics_with_prune.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    feature_importance_dict = {\n",
    "        f\"Feature {i}\": importance \n",
    "        for i, importance in enumerate(model_no_prune.feature_importances_)\n",
    "    }\n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for feature, importance in sorted_features:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "    return model_no_prune, model_with_prune, grid_search_results, test_metrics_no_prune, test_metrics_with_prune\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    primary_path = \"C:/Users/ikry/Downloads/secondary+mushroom+dataset/MushroomDataset/MushroomDataset/primary_data.csv\"\n",
    "    secondary_path = \"C:/Users/ikry/Downloads/secondary+mushroom+dataset/MushroomDataset/MushroomDataset/secondary_data.csv\"\n",
    "\n",
    "X_single, y_single, X_merged, y_merged = data_preprocessing(primary_path, secondary_path, sample_ratio=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_merged, y_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "model_no_prune, model_with_prune, grid_results, metrics_no_prune, metrics_with_prune = run_mushroom_classification(X_merged, y_merged)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d80446-eac5-4540-a19e-454a0bb73cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaDKernel",
   "language": "python",
   "name": "ladkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
